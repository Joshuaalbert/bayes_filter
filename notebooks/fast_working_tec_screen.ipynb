{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 00:36:13.878483 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0719 00:36:13.882695 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0719 00:36:14.028628 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "W0719 00:36:14.077193 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/bayes_filter-0.0.1-py3.6.egg/bayes_filter/__init__.py:4: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0719 00:36:14.078356 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/bayes_filter-0.0.1-py3.6.egg/bayes_filter/__init__.py:4: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "I0719 00:36:14.952858 140342669231936 <ipython-input-1-97e343f66720>:261] Training on 35 antennas\n",
      "W0719 00:36:15.106472 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/core/node.py:109: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "I0719 00:36:16.821298 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 30 outliers\n",
      "W0719 00:36:16.843262 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/params/parameter.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 00:36:16.846990 140342669231936 deprecation_wrapper.py:119] From /net/lofar1/data1/albert/miniconda3/envs/bayes_filter/lib/python3.6/site-packages/gpflow-1.3.0-py3.6.egg/gpflow/params/parameter.py:394: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "I0719 00:36:18.269936 140342669231936 <ipython-input-1-97e343f66720>:382] Index 0 -> training hyperparams\n",
      "I0719 00:36:23.487661 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 5.44s\n",
      "num acquisition: 2, time elapsed: 11.17s\n",
      "num acquisition: 3, time elapsed: 17.24s\n",
      "num acquisition: 4, time elapsed: 23.43s\n",
      "num acquisition: 5, time elapsed: 29.26s\n",
      "num acquisition: 6, time elapsed: 35.07s\n",
      "num acquisition: 7, time elapsed: 41.53s\n",
      "num acquisition: 8, time elapsed: 47.24s\n",
      "num acquisition: 9, time elapsed: 53.60s\n",
      "num acquisition: 10, time elapsed: 59.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:39:43.586354 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(157.55019547), 'HGPR/kern/lengthscales': array(6.19872958), 'HGPR/kern/variance': array(8.79984506)}\n",
      "I0719 00:39:43.588170 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 0 -> training hyperparams\n",
      "I0719 00:39:44.978262 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 0 to 40\n",
      "I0719 00:41:29.331870 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 0 to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:42:21.072885 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 00:42:22.144308 140342669231936 <ipython-input-1-97e343f66720>:382] Index 40 -> training hyperparams\n",
      "I0719 00:42:27.222161 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 6.52s\n",
      "num acquisition: 2, time elapsed: 12.82s\n",
      "num acquisition: 3, time elapsed: 19.54s\n",
      "num acquisition: 4, time elapsed: 25.87s\n",
      "num acquisition: 5, time elapsed: 32.59s\n",
      "num acquisition: 6, time elapsed: 39.69s\n",
      "num acquisition: 7, time elapsed: 46.40s\n",
      "num acquisition: 8, time elapsed: 53.42s\n",
      "num acquisition: 9, time elapsed: 60.39s\n",
      "num acquisition: 10, time elapsed: 66.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:46:04.370659 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(114.26158754), 'HGPR/kern/lengthscales': array(5.26142624), 'HGPR/kern/variance': array(13.83519863)}\n",
      "I0719 00:46:04.372250 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 40 -> training hyperparams\n",
      "I0719 00:46:05.986730 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 40 to 80\n",
      "I0719 00:47:51.329965 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 40 to 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:48:43.583114 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 00:48:44.855223 140342669231936 <ipython-input-1-97e343f66720>:382] Index 80 -> training hyperparams\n",
      "I0719 00:48:49.992711 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 7.09s\n",
      "num acquisition: 2, time elapsed: 14.53s\n",
      "num acquisition: 3, time elapsed: 22.12s\n",
      "num acquisition: 4, time elapsed: 29.38s\n",
      "num acquisition: 5, time elapsed: 37.02s\n",
      "num acquisition: 6, time elapsed: 44.42s\n",
      "num acquisition: 7, time elapsed: 51.85s\n",
      "num acquisition: 8, time elapsed: 59.54s\n",
      "num acquisition: 9, time elapsed: 67.02s\n",
      "num acquisition: 10, time elapsed: 74.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:52:56.822824 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(114.26158754), 'HGPR/kern/lengthscales': array(5.26142624), 'HGPR/kern/variance': array(13.83519863)}\n",
      "I0719 00:52:56.824388 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 80 -> training hyperparams\n",
      "I0719 00:52:58.187330 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 80 to 120\n",
      "I0719 00:54:43.353981 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 80 to 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 00:55:35.177467 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 79 outliers\n",
      "I0719 00:55:36.567428 140342669231936 <ipython-input-1-97e343f66720>:382] Index 120 -> training hyperparams\n",
      "I0719 00:55:41.653371 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 8.83s\n",
      "num acquisition: 2, time elapsed: 17.32s\n",
      "num acquisition: 3, time elapsed: 25.08s\n",
      "num acquisition: 4, time elapsed: 33.85s\n",
      "num acquisition: 5, time elapsed: 41.68s\n",
      "num acquisition: 6, time elapsed: 50.41s\n",
      "num acquisition: 7, time elapsed: 58.52s\n",
      "num acquisition: 8, time elapsed: 67.38s\n",
      "num acquisition: 9, time elapsed: 75.33s\n",
      "num acquisition: 10, time elapsed: 84.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:00:11.722556 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(114.26158754), 'HGPR/kern/lengthscales': array(5.26142624), 'HGPR/kern/variance': array(13.83519863)}\n",
      "I0719 01:00:11.724101 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 120 -> training hyperparams\n",
      "I0719 01:00:13.303838 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 120 to 160\n",
      "I0719 01:02:00.418477 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 120 to 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:02:52.077686 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 130 outliers\n",
      "I0719 01:02:53.705386 140342669231936 <ipython-input-1-97e343f66720>:382] Index 160 -> training hyperparams\n",
      "I0719 01:02:59.015128 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 9.95s\n",
      "num acquisition: 2, time elapsed: 19.59s\n",
      "num acquisition: 3, time elapsed: 30.04s\n",
      "num acquisition: 4, time elapsed: 40.17s\n",
      "num acquisition: 5, time elapsed: 49.13s\n",
      "num acquisition: 6, time elapsed: 58.04s\n",
      "num acquisition: 7, time elapsed: 67.50s\n",
      "num acquisition: 8, time elapsed: 78.36s\n",
      "num acquisition: 9, time elapsed: 87.96s\n",
      "num acquisition: 10, time elapsed: 96.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:08:02.417151 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(170.28943015), 'HGPR/kern/lengthscales': array(5.41555249), 'HGPR/kern/variance': array(55.57637703)}\n",
      "I0719 01:08:02.418615 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 160 -> training hyperparams\n",
      "I0719 01:08:05.582630 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 160 to 200\n",
      "I0719 01:09:51.029620 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 160 to 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:10:42.702003 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 136 outliers\n",
      "I0719 01:10:44.510877 140342669231936 <ipython-input-1-97e343f66720>:382] Index 200 -> training hyperparams\n",
      "I0719 01:10:49.911607 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 8.20s\n",
      "num acquisition: 2, time elapsed: 19.35s\n",
      "num acquisition: 3, time elapsed: 28.26s\n",
      "num acquisition: 4, time elapsed: 36.93s\n",
      "num acquisition: 5, time elapsed: 45.69s\n",
      "num acquisition: 6, time elapsed: 57.33s\n",
      "num acquisition: 7, time elapsed: 65.97s\n",
      "num acquisition: 8, time elapsed: 74.43s\n",
      "num acquisition: 9, time elapsed: 87.13s\n",
      "num acquisition: 10, time elapsed: 98.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:16:11.235219 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(170.28943015), 'HGPR/kern/lengthscales': array(5.41555249), 'HGPR/kern/variance': array(55.57637703)}\n",
      "I0719 01:16:11.238000 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 200 -> training hyperparams\n",
      "I0719 01:16:17.811574 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 200 to 240\n",
      "I0719 01:18:04.983832 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 200 to 240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:18:57.231592 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 118 outliers\n",
      "I0719 01:18:59.184664 140342669231936 <ipython-input-1-97e343f66720>:382] Index 240 -> training hyperparams\n",
      "I0719 01:19:04.799545 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 13.00s\n",
      "num acquisition: 2, time elapsed: 22.97s\n",
      "num acquisition: 3, time elapsed: 34.20s\n",
      "num acquisition: 4, time elapsed: 46.20s\n",
      "num acquisition: 5, time elapsed: 58.23s\n",
      "num acquisition: 6, time elapsed: 71.47s\n",
      "num acquisition: 7, time elapsed: 83.83s\n",
      "num acquisition: 8, time elapsed: 97.86s\n",
      "num acquisition: 9, time elapsed: 110.38s\n",
      "num acquisition: 10, time elapsed: 123.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:25:34.014438 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(170.28943015), 'HGPR/kern/lengthscales': array(5.41555249), 'HGPR/kern/variance': array(55.57637703)}\n",
      "I0719 01:25:34.017281 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 240 -> training hyperparams\n",
      "I0719 01:25:36.962244 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 240 to 280\n",
      "I0719 01:27:24.270636 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 240 to 280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:28:24.047096 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 96 outliers\n",
      "I0719 01:28:27.003532 140342669231936 <ipython-input-1-97e343f66720>:382] Index 280 -> training hyperparams\n",
      "I0719 01:28:32.923970 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 9.95s\n",
      "num acquisition: 2, time elapsed: 19.89s\n",
      "num acquisition: 3, time elapsed: 30.14s\n",
      "num acquisition: 4, time elapsed: 43.77s\n",
      "num acquisition: 5, time elapsed: 58.75s\n",
      "num acquisition: 6, time elapsed: 73.45s\n",
      "num acquisition: 7, time elapsed: 86.72s\n",
      "num acquisition: 8, time elapsed: 98.88s\n",
      "num acquisition: 9, time elapsed: 110.92s\n",
      "num acquisition: 10, time elapsed: 124.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:35:17.939868 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(137.81074834), 'HGPR/kern/lengthscales': array(3.8676412), 'HGPR/kern/variance': array(22.12673944)}\n",
      "I0719 01:35:17.943291 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 280 -> training hyperparams\n",
      "I0719 01:35:21.005014 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 280 to 320\n",
      "I0719 01:37:07.606180 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 280 to 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:38:01.114984 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 46 outliers\n",
      "I0719 01:38:09.744766 140342669231936 <ipython-input-1-97e343f66720>:382] Index 320 -> training hyperparams\n",
      "I0719 01:38:15.524631 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 15.96s\n",
      "num acquisition: 2, time elapsed: 27.03s\n",
      "num acquisition: 3, time elapsed: 38.20s\n",
      "num acquisition: 4, time elapsed: 50.83s\n",
      "num acquisition: 5, time elapsed: 66.53s\n",
      "num acquisition: 6, time elapsed: 82.71s\n",
      "num acquisition: 7, time elapsed: 99.36s\n",
      "num acquisition: 8, time elapsed: 114.27s\n",
      "num acquisition: 9, time elapsed: 127.26s\n",
      "num acquisition: 10, time elapsed: 142.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:45:36.374570 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(140.33818772), 'HGPR/kern/lengthscales': array(1.81922736), 'HGPR/kern/variance': array(0.73575294)}\n",
      "I0719 01:45:36.376379 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 320 -> training hyperparams\n",
      "I0719 01:45:39.370311 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 320 to 360\n",
      "I0719 01:47:26.440176 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 320 to 360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:48:20.603169 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 185 outliers\n",
      "I0719 01:48:23.363029 140342669231936 <ipython-input-1-97e343f66720>:382] Index 360 -> training hyperparams\n",
      "I0719 01:48:29.281250 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 17.61s\n",
      "num acquisition: 2, time elapsed: 30.53s\n",
      "num acquisition: 3, time elapsed: 48.01s\n",
      "num acquisition: 4, time elapsed: 63.22s\n",
      "num acquisition: 5, time elapsed: 76.49s\n",
      "num acquisition: 6, time elapsed: 91.30s\n",
      "num acquisition: 7, time elapsed: 104.84s\n",
      "num acquisition: 8, time elapsed: 117.01s\n",
      "num acquisition: 9, time elapsed: 132.67s\n",
      "num acquisition: 10, time elapsed: 144.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:56:21.035138 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(142.6014633), 'HGPR/kern/lengthscales': array(1.55541184), 'HGPR/kern/variance': array(1.04245007)}\n",
      "I0719 01:56:21.037780 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 360 -> training hyperparams\n",
      "I0719 01:56:24.118966 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 360 to 400\n",
      "I0719 01:58:11.374835 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 360 to 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 01:59:05.700206 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 10 outliers\n",
      "I0719 01:59:13.196778 140342669231936 <ipython-input-1-97e343f66720>:382] Index 400 -> training hyperparams\n",
      "I0719 01:59:19.466582 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 13.02s\n",
      "num acquisition: 2, time elapsed: 26.22s\n",
      "num acquisition: 3, time elapsed: 47.09s\n",
      "num acquisition: 4, time elapsed: 62.14s\n",
      "num acquisition: 5, time elapsed: 79.14s\n",
      "num acquisition: 6, time elapsed: 94.27s\n",
      "num acquisition: 7, time elapsed: 107.50s\n",
      "num acquisition: 8, time elapsed: 126.40s\n",
      "num acquisition: 9, time elapsed: 145.85s\n",
      "num acquisition: 10, time elapsed: 166.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:07:58.203983 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(136.93396255), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 02:07:58.206814 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 400 -> training hyperparams\n",
      "I0719 02:08:01.554998 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 400 to 440\n",
      "I0719 02:09:47.643372 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 400 to 440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:10:45.532635 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 02:10:48.648083 140342669231936 <ipython-input-1-97e343f66720>:382] Index 440 -> training hyperparams\n",
      "I0719 02:10:54.774700 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 13.68s\n",
      "num acquisition: 2, time elapsed: 27.26s\n",
      "num acquisition: 3, time elapsed: 43.55s\n",
      "num acquisition: 4, time elapsed: 62.95s\n",
      "num acquisition: 5, time elapsed: 80.03s\n",
      "num acquisition: 6, time elapsed: 101.50s\n",
      "num acquisition: 7, time elapsed: 119.19s\n",
      "num acquisition: 8, time elapsed: 133.63s\n",
      "num acquisition: 9, time elapsed: 148.00s\n",
      "num acquisition: 10, time elapsed: 161.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:20:00.613419 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(134.16624465), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 02:20:00.617029 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 440 -> training hyperparams\n",
      "I0719 02:20:05.204049 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 440 to 480\n",
      "I0719 02:21:52.629001 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 440 to 480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:22:50.393889 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 02:22:55.892330 140342669231936 <ipython-input-1-97e343f66720>:382] Index 480 -> training hyperparams\n",
      "I0719 02:23:03.591851 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 19.75s\n",
      "num acquisition: 2, time elapsed: 38.19s\n",
      "num acquisition: 3, time elapsed: 57.44s\n",
      "num acquisition: 4, time elapsed: 72.85s\n",
      "num acquisition: 5, time elapsed: 92.39s\n",
      "num acquisition: 6, time elapsed: 107.38s\n",
      "num acquisition: 7, time elapsed: 131.24s\n",
      "num acquisition: 8, time elapsed: 151.78s\n",
      "num acquisition: 9, time elapsed: 172.99s\n",
      "num acquisition: 10, time elapsed: 194.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:33:08.806250 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(130.86351312), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 02:33:08.809689 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 480 -> training hyperparams\n",
      "I0719 02:33:12.873345 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 480 to 520\n",
      "I0719 02:35:01.153296 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 480 to 520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:36:05.629693 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 02:36:09.351267 140342669231936 <ipython-input-1-97e343f66720>:382] Index 520 -> training hyperparams\n",
      "I0719 02:36:16.164585 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 22.86s\n",
      "num acquisition: 2, time elapsed: 48.18s\n",
      "num acquisition: 3, time elapsed: 69.34s\n",
      "num acquisition: 4, time elapsed: 92.26s\n",
      "num acquisition: 5, time elapsed: 112.73s\n",
      "num acquisition: 6, time elapsed: 136.66s\n",
      "num acquisition: 7, time elapsed: 154.75s\n",
      "num acquisition: 8, time elapsed: 176.78s\n",
      "num acquisition: 9, time elapsed: 201.08s\n",
      "num acquisition: 10, time elapsed: 226.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:47:15.726640 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(130.86351312), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 02:47:15.729138 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 520 -> training hyperparams\n",
      "I0719 02:47:20.207402 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 520 to 560\n",
      "I0719 02:49:07.884107 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 520 to 560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 02:50:08.249567 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 02:50:15.642688 140342669231936 <ipython-input-1-97e343f66720>:382] Index 560 -> training hyperparams\n",
      "I0719 02:50:24.406599 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 25.55s\n",
      "num acquisition: 2, time elapsed: 48.33s\n",
      "num acquisition: 3, time elapsed: 71.93s\n",
      "num acquisition: 4, time elapsed: 93.42s\n",
      "num acquisition: 5, time elapsed: 111.97s\n",
      "num acquisition: 6, time elapsed: 135.84s\n",
      "num acquisition: 7, time elapsed: 159.63s\n",
      "num acquisition: 8, time elapsed: 184.63s\n",
      "num acquisition: 9, time elapsed: 206.11s\n",
      "num acquisition: 10, time elapsed: 234.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:02:24.996027 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(128.88352457), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 03:02:24.999877 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 560 -> training hyperparams\n",
      "I0719 03:02:29.692734 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 560 to 600\n",
      "I0719 03:04:19.528885 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 560 to 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:05:17.647817 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 03:05:21.898301 140342669231936 <ipython-input-1-97e343f66720>:382] Index 600 -> training hyperparams\n",
      "I0719 03:05:28.817757 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 25.77s\n",
      "num acquisition: 2, time elapsed: 43.42s\n",
      "num acquisition: 3, time elapsed: 68.71s\n",
      "num acquisition: 4, time elapsed: 95.86s\n",
      "num acquisition: 5, time elapsed: 116.00s\n",
      "num acquisition: 6, time elapsed: 134.20s\n",
      "num acquisition: 7, time elapsed: 152.25s\n",
      "num acquisition: 8, time elapsed: 178.59s\n",
      "num acquisition: 9, time elapsed: 198.17s\n",
      "num acquisition: 10, time elapsed: 218.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:17:43.074565 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(128.88352457), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 03:17:43.077019 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 600 -> training hyperparams\n",
      "I0719 03:17:47.810950 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 600 to 640\n",
      "I0719 03:19:38.552653 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 600 to 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:20:46.959413 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 03:20:51.444550 140342669231936 <ipython-input-1-97e343f66720>:382] Index 640 -> training hyperparams\n",
      "I0719 03:20:58.559413 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 27.94s\n",
      "num acquisition: 2, time elapsed: 54.16s\n",
      "num acquisition: 3, time elapsed: 78.51s\n",
      "num acquisition: 4, time elapsed: 100.43s\n",
      "num acquisition: 5, time elapsed: 117.77s\n",
      "num acquisition: 6, time elapsed: 146.12s\n",
      "num acquisition: 7, time elapsed: 168.39s\n",
      "num acquisition: 8, time elapsed: 192.69s\n",
      "num acquisition: 9, time elapsed: 217.92s\n",
      "num acquisition: 10, time elapsed: 244.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:33:10.726771 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 03:33:10.734641 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 640 -> training hyperparams\n",
      "I0719 03:33:15.319878 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 640 to 680\n",
      "I0719 03:35:04.300887 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 640 to 680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:36:01.481032 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 03:36:05.934603 140342669231936 <ipython-input-1-97e343f66720>:382] Index 680 -> training hyperparams\n",
      "I0719 03:36:13.156475 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 24.21s\n",
      "num acquisition: 2, time elapsed: 43.05s\n",
      "num acquisition: 3, time elapsed: 74.14s\n",
      "num acquisition: 4, time elapsed: 97.12s\n",
      "num acquisition: 5, time elapsed: 115.64s\n",
      "num acquisition: 6, time elapsed: 145.29s\n",
      "num acquisition: 7, time elapsed: 173.31s\n",
      "num acquisition: 8, time elapsed: 197.32s\n",
      "num acquisition: 9, time elapsed: 217.03s\n",
      "num acquisition: 10, time elapsed: 235.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:49:21.215090 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 03:49:21.219015 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 680 -> training hyperparams\n",
      "I0719 03:49:29.774446 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 680 to 720\n",
      "I0719 03:51:23.020203 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 680 to 720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 03:52:28.955915 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 03:52:35.648320 140342669231936 <ipython-input-1-97e343f66720>:382] Index 720 -> training hyperparams\n",
      "I0719 03:52:43.914238 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 21.04s\n",
      "num acquisition: 2, time elapsed: 44.28s\n",
      "num acquisition: 3, time elapsed: 69.29s\n",
      "num acquisition: 4, time elapsed: 96.54s\n",
      "num acquisition: 5, time elapsed: 119.45s\n",
      "num acquisition: 6, time elapsed: 140.13s\n",
      "num acquisition: 7, time elapsed: 169.36s\n",
      "num acquisition: 8, time elapsed: 197.94s\n",
      "num acquisition: 9, time elapsed: 218.82s\n",
      "num acquisition: 10, time elapsed: 240.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:06:24.021828 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 04:06:24.024512 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 720 -> training hyperparams\n",
      "I0719 04:06:34.519288 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 720 to 760\n",
      "I0719 04:08:28.715741 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 720 to 760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:09:32.181452 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 04:09:37.650482 140342669231936 <ipython-input-1-97e343f66720>:382] Index 760 -> training hyperparams\n",
      "I0719 04:09:45.513941 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 29.75s\n",
      "num acquisition: 2, time elapsed: 50.89s\n",
      "num acquisition: 3, time elapsed: 87.79s\n",
      "num acquisition: 4, time elapsed: 113.50s\n",
      "num acquisition: 5, time elapsed: 141.32s\n",
      "num acquisition: 6, time elapsed: 162.96s\n",
      "num acquisition: 7, time elapsed: 185.28s\n",
      "num acquisition: 8, time elapsed: 207.46s\n",
      "num acquisition: 9, time elapsed: 238.51s\n",
      "num acquisition: 10, time elapsed: 260.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:24:53.732685 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 04:24:53.735090 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 760 -> training hyperparams\n",
      "I0719 04:24:59.716748 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 760 to 800\n",
      "I0719 04:27:05.890476 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 760 to 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:28:05.848589 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 04:28:11.816684 140342669231936 <ipython-input-1-97e343f66720>:382] Index 800 -> training hyperparams\n",
      "I0719 04:28:20.007255 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 31.34s\n",
      "num acquisition: 2, time elapsed: 61.91s\n",
      "num acquisition: 3, time elapsed: 83.58s\n",
      "num acquisition: 4, time elapsed: 105.39s\n",
      "num acquisition: 5, time elapsed: 137.75s\n",
      "num acquisition: 6, time elapsed: 167.26s\n",
      "num acquisition: 7, time elapsed: 190.00s\n",
      "num acquisition: 8, time elapsed: 213.15s\n",
      "num acquisition: 9, time elapsed: 249.48s\n",
      "num acquisition: 10, time elapsed: 279.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:44:27.642884 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 04:44:27.646642 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 800 -> training hyperparams\n",
      "I0719 04:44:34.025902 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 800 to 840\n",
      "I0719 04:46:27.679143 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 800 to 840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 04:47:29.267551 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 04:47:35.460847 140342669231936 <ipython-input-1-97e343f66720>:382] Index 840 -> training hyperparams\n",
      "I0719 04:47:44.130746 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 33.84s\n",
      "num acquisition: 2, time elapsed: 59.60s\n",
      "num acquisition: 3, time elapsed: 99.00s\n",
      "num acquisition: 4, time elapsed: 127.22s\n",
      "num acquisition: 5, time elapsed: 151.33s\n",
      "num acquisition: 6, time elapsed: 184.70s\n",
      "num acquisition: 7, time elapsed: 208.83s\n",
      "num acquisition: 8, time elapsed: 238.92s\n",
      "num acquisition: 9, time elapsed: 262.58s\n",
      "num acquisition: 10, time elapsed: 294.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:05:07.794438 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(101.82548253), 'HGPR/kern/lengthscales': array(1.), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 05:05:07.797447 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 840 -> training hyperparams\n",
      "I0719 05:05:14.525806 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 840 to 880\n",
      "I0719 05:07:08.712380 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 840 to 880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:08:11.174297 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 05:08:23.405319 140342669231936 <ipython-input-1-97e343f66720>:382] Index 880 -> training hyperparams\n",
      "I0719 05:08:35.260685 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 37.49s\n",
      "num acquisition: 2, time elapsed: 70.26s\n",
      "num acquisition: 3, time elapsed: 110.92s\n",
      "num acquisition: 4, time elapsed: 144.03s\n",
      "num acquisition: 5, time elapsed: 168.60s\n",
      "num acquisition: 6, time elapsed: 193.42s\n",
      "num acquisition: 7, time elapsed: 218.29s\n",
      "num acquisition: 8, time elapsed: 252.58s\n",
      "num acquisition: 9, time elapsed: 286.68s\n",
      "num acquisition: 10, time elapsed: 320.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:27:18.296924 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(104.53963661), 'HGPR/kern/lengthscales': array(1.36821332), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 05:27:18.300513 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 880 -> training hyperparams\n",
      "I0719 05:27:25.544960 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 880 to 920\n",
      "I0719 05:29:20.053020 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 880 to 920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:30:35.788090 140342669231936 <ipython-input-1-97e343f66720>:379] Predicting with 0 outliers\n",
      "I0719 05:30:47.673275 140342669231936 <ipython-input-1-97e343f66720>:382] Index 920 -> training hyperparams\n",
      "I0719 05:30:57.635192 140342669231936 <ipython-input-1-97e343f66720>:385] Doing bayesian optimisation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 34.30s\n",
      "num acquisition: 2, time elapsed: 69.81s\n",
      "num acquisition: 3, time elapsed: 96.00s\n",
      "num acquisition: 4, time elapsed: 134.69s\n",
      "num acquisition: 5, time elapsed: 160.26s\n",
      "num acquisition: 6, time elapsed: 207.14s\n",
      "num acquisition: 7, time elapsed: 241.35s\n",
      "num acquisition: 8, time elapsed: 277.91s\n",
      "num acquisition: 9, time elapsed: 313.81s\n",
      "num acquisition: 10, time elapsed: 351.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:49:44.033811 140342669231936 <ipython-input-1-97e343f66720>:449] {'HGPR/kern/a': array(104.53963661), 'HGPR/kern/lengthscales': array(1.36821332), 'HGPR/kern/variance': array(0.25)}\n",
      "I0719 05:49:44.037523 140342669231936 <ipython-input-1-97e343f66720>:450] Done index 920 -> training hyperparams\n",
      "I0719 05:49:53.528676 140342669231936 <ipython-input-1-97e343f66720>:454] Predicting screen from 920 to 960\n",
      "I0719 05:51:54.211076 140342669231936 <ipython-input-1-97e343f66720>:465] Done predicting screen from 920 to 960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 05:52:59.601008 140342669231936 <ipython-input-1-97e343f66720>:503] Storing\n",
      "I0719 05:52:59.964407 140342669231936 <ipython-input-1-97e343f66720>:513] Done\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import GPyOpt\n",
    "import GPy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import astropy.time as at\n",
    "import astropy.coordinates as ac\n",
    "import astropy.units as au\n",
    "import gpflow as gp\n",
    "from bayes_filter.datapack import DataPack\n",
    "from bayes_filter.misc import make_coord_array, get_screen_directions\n",
    "from bayes_filter.coord_transforms import ITRSToENUWithReferences\n",
    "from bayes_filter.settings import dist_type, angle_type\n",
    "from bayes_filter.kernels import DTECIsotropicTimeGeneral\n",
    "from bayes_filter.plotting import plot_vornoi_map\n",
    "from bayes_filter import logging\n",
    "import pylab as plt\n",
    "from scipy.special import erf\n",
    "\n",
    "from functools import reduce\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gpflow as gp\n",
    "\n",
    "from gpflow import transforms\n",
    "from gpflow import settings\n",
    "\n",
    "from gpflow.params import Parameter, Parameterized, ParamList\n",
    "from gpflow.decors import params_as_tensors, autoflow\n",
    "\n",
    "float_type = settings.float_type\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class DTECKernel(gp.kernels.Kernel):\n",
    "    def __init__(self, input_dim, variance=1., lengthscales=10.0,\n",
    "                 a=200., b=100., resolution=10,\n",
    "                 active_dims=None, fed_kernel='RBF', obs_type='DTEC', name=None):\n",
    "        \"\"\"\n",
    "        - input_dim is the dimension of the input to the kernel\n",
    "        - variance is the (initial) value for the variance parameter\n",
    "        - lengthscales is the initial value for the lengthscales parameter\n",
    "          defaults to 1.0 (ARD=False) or np.ones(input_dim) (ARD=True).\n",
    "        - active_dims is a list of length input_dim which controls which\n",
    "          columns of X are used.\n",
    "        \"\"\"\n",
    "        super().__init__(input_dim, active_dims, name=name)\n",
    "        self.variance = Parameter(variance, transform=transforms.positiveRescale(variance),\n",
    "                                  dtype=settings.float_type)\n",
    "        # (3,)\n",
    "        self.lengthscales = Parameter(lengthscales, transform=transforms.positiveRescale(lengthscales),\n",
    "                                      dtype=settings.float_type)\n",
    "        self.a = Parameter(a, transform=transforms.positiveRescale(a),\n",
    "                           dtype=settings.float_type)\n",
    "        self.b = Parameter(b, transform=transforms.positiveRescale(b),\n",
    "                           dtype=settings.float_type)\n",
    "        self.resolution = resolution\n",
    "        self.obs_type = obs_type\n",
    "        self.fed_kernel = fed_kernel\n",
    "\n",
    "    @params_as_tensors\n",
    "    def Kdiag(self, X, presliced=False):\n",
    "        if not presliced:\n",
    "            X, _ = self._slice(X, None)\n",
    "        return tf.diag_part(self.K(X, None))\n",
    "\n",
    "    @params_as_tensors\n",
    "    def K(self, X, X2=None, presliced=False):\n",
    "\n",
    "        if not presliced:\n",
    "            X, X2 = self._slice(X, X2)\n",
    "\n",
    "        kern = DTECIsotropicTimeGeneral(variance=self.variance, lengthscales=self.lengthscales,\n",
    "                                        a=self.a, b=self.b, fed_kernel=self.fed_kernel, obs_type=self.obs_type,\n",
    "                                        squeeze=True,  # ode_type='adaptive',\n",
    "                                        kernel_params={'resolution': self.resolution})\n",
    "        return kern.K(X, X2)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpflow import likelihoods\n",
    "from gpflow import settings\n",
    "\n",
    "from gpflow.conditionals import base_conditional\n",
    "from gpflow.params import DataHolder\n",
    "from gpflow.decors import params_as_tensors\n",
    "from gpflow.decors import name_scope\n",
    "from gpflow.logdensities import multivariate_normal\n",
    "\n",
    "from gpflow.models.model import GPModel\n",
    "\n",
    "\n",
    "class HGPR(GPModel):\n",
    "    r\"\"\"\n",
    "    Gaussian Process Regression.\n",
    "    This is a vanilla implementation of GP regression with a Gaussian\n",
    "    likelihood. In this case inference is exact, but costs O(N^3). This means\n",
    "    that we can compute the predictive distributions (predict_f, predict_y) in\n",
    "    closed-form, as well as the marginal likelihood, which we use to estimate\n",
    "    (optimize) the kernel parameters.\n",
    "\n",
    "    Multiple columns of Y are treated independently, using the same kernel.\n",
    "    The log likelihood of this model is sometimes referred to as the\n",
    "    'marginal log likelihood', and is given by\n",
    "    .. math::\n",
    "       \\log p(\\mathbf y | \\mathbf f) = \\mathcal N(\\mathbf y | 0, \\mathbf K + \\sigma_n \\mathbf I)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, Y_var, kern, mean_function=None, parallel_iterations=1, name=None):\n",
    "        \"\"\"\n",
    "        X is a data matrix, size N x D\n",
    "        Y is a data matrix, size N x R\n",
    "        kern, mean_function are appropriate GPflow objects\n",
    "        name is a string which can be used to name this model (useful for handling multiple models on one tf.graph)\n",
    "        \"\"\"\n",
    "        likelihood = likelihoods.Gaussian()\n",
    "        # M, D\n",
    "        X = DataHolder(X)\n",
    "        # T, M\n",
    "        Y = DataHolder(Y)\n",
    "        num_latent = Y.shape[0]\n",
    "        GPModel.__init__(self, X=X, Y=Y, kern=kern, likelihood=likelihood,\n",
    "                         mean_function=mean_function, num_latent=num_latent, name=name)\n",
    "        self.Y_var = DataHolder(Y_var)\n",
    "        self.parallel_iterations = parallel_iterations\n",
    "\n",
    "    @name_scope('likelihood')\n",
    "    @params_as_tensors\n",
    "    def _build_likelihood(self):\n",
    "        r\"\"\"\n",
    "        Construct a tensorflow function to compute the likelihood.\n",
    "            \\log p(Y | theta).\n",
    "        \"\"\"\n",
    "        # M,M + T, M, M -> T, M, M\n",
    "        K = self.kern.K(self.X)\n",
    "        Y_std = tf.math.sqrt(self.Y_var)\n",
    "\n",
    "        def single_marginal(args):\n",
    "            y, y_std = args\n",
    "            M = tf.shape(y_std)[0]\n",
    "            K_sigma = K / (y_std[:, None] * y_std[None, :]) + tf.linalg.eye(M, dtype=float_type)\n",
    "            L = tf.linalg.cholesky(K_sigma)\n",
    "            y /= y_std\n",
    "            A = tf.linalg.triangular_solve(L, y[:, None])\n",
    "            maha = -0.5 * tf.reduce_sum(tf.math.square(A))\n",
    "            # (sigma.L.L^T.sigma^T)^-1 = sigma^-T.L^-T.L^-1 sigma^-1\n",
    "            # log(0) + log(infty) -> 0\n",
    "            logdetL = tf.reduce_sum(\n",
    "                tf.math.log(\n",
    "                    tf.where(tf.equal(y_std, tf.constant(np.inf, float_type)),\n",
    "                             tf.ones_like(y_std),\n",
    "                             tf.linalg.diag_part(L) * y_std)\n",
    "                )\n",
    "            )\n",
    "            constant = 0.5 * np.log(np.sqrt(2. * np.pi)) * tf.cast(M, float_type)\n",
    "            return maha - logdetL - constant\n",
    "\n",
    "        logpdf = tf.map_fn(single_marginal, [self.Y, Y_std], float_type, parallel_iterations=self.parallel_iterations)\n",
    "\n",
    "        return tf.reduce_sum(logpdf)\n",
    "\n",
    "    @name_scope('predict')\n",
    "    @params_as_tensors\n",
    "    def _build_predict(self, Xnew, full_cov=False):\n",
    "        \"\"\"\n",
    "        Xnew is a data matrix, the points at which we want to predict.\n",
    "        This method computes\n",
    "            p(F* | Y)\n",
    "        where F* are points on the GP at Xnew, Y are noisy observations at X.\n",
    "        \"\"\"\n",
    "\n",
    "        # T,M,M\n",
    "        Kmm = self.kern.K(self.X)\n",
    "        # M,N\n",
    "        Kmn = self.kern.K(self.X, Xnew)\n",
    "        Knn = self.kern.K(Xnew) if full_cov else self.kern.Kdiag(Xnew)\n",
    "\n",
    "        Y_std = tf.math.sqrt(self.Y_var)\n",
    "\n",
    "        def single_predict_f(args):\n",
    "            y, y_std = args\n",
    "            M = tf.shape(y_std)[0]\n",
    "            # M,M\n",
    "            Kmm_sigma = Kmm / (y_std[:, None] * y_std[None, :]) + tf.linalg.eye(M, dtype=float_type)\n",
    "            # (sigma.L.L^T.sigma^T)^-1 = sigma^-T.L^-T.L^-1 sigma^-1\n",
    "            # M,M\n",
    "            L = tf.linalg.cholesky(Kmm_sigma)\n",
    "            # M,N\n",
    "            A = tf.linalg.triangular_solve(L, Kmn / y_std[:, None])\n",
    "            # N\n",
    "            post_mean = tf.matmul(A, tf.linalg.triangular_solve(L, y[:, None] / y_std[:, None]), transpose_a=True)[:, 0]\n",
    "            if full_cov:\n",
    "                # N,N\n",
    "                post_cov = Knn - tf.matmul(A, A, transpose_a=True)\n",
    "            else:\n",
    "                # N\n",
    "                # sum_k A[k,i]A[k,j]\n",
    "                # N + T,N -> T,N\n",
    "                post_cov = Knn - tf.reduce_mean(tf.math.square(A), axis=0)\n",
    "            return [post_mean, post_cov]\n",
    "\n",
    "        post_mean, post_cov = tf.map_fn(single_predict_f, [self.Y, Y_std], [float_type, float_type],\n",
    "                                        parallel_iterations=self.parallel_iterations)\n",
    "        return post_mean, post_cov\n",
    "\n",
    "\n",
    "# %%\n",
    "reinout_datapack = '/home/albert/lofar1_1/imaging/data/P126+65_compact_raw/P126+65_full_compact_raw_v6.h5'\n",
    "datapack = DataPack(reinout_datapack, readonly=False)\n",
    "select = dict(pol=slice(0, 1, 1),\n",
    "              ant=slice(None, None, 1),\n",
    "              dir=slice(None, None, 1),\n",
    "              time=slice(None, None, 1))\n",
    "datapack.current_solset = 'data_posterior'\n",
    "datapack.select(**select)\n",
    "\n",
    "tec, _ = datapack.tec\n",
    "tec[:, 14, ...] = 0.\n",
    "datapack.tec = tec\n",
    "\n",
    "# Nd, Na, Nt\n",
    "reinout_flags = np.load('/home/albert/lofar1_1/imaging/data/flagsTECBay.npy')\n",
    "reinout_flags = np.where(reinout_flags == 1., np.inf, 0.5)  # uncertainty in mTECU\n",
    "datapack.weights_tec = reinout_flags\n",
    "\n",
    "recalculate_weights = False\n",
    "ant_cutoff = 0.15\n",
    "ref_dir_idx = 14\n",
    "block_size = 40\n",
    "\n",
    "datapack = DataPack(reinout_datapack, readonly=True)\n",
    "select = dict(pol=slice(0, 1, 1),\n",
    "              ant=slice(None, None, 1),\n",
    "              dir=slice(None, None, 1),\n",
    "              time=slice(None, None, 1))\n",
    "datapack.current_solset = 'data_posterior'\n",
    "datapack.select(**select)\n",
    "axes = datapack.axes_tec\n",
    "\n",
    "###\n",
    "# cutoff dist for antennas\n",
    "ants, antennas = datapack.get_antennas(axes['ant'])\n",
    "Xa = antennas.cartesian.xyz.to(dist_type).value.T\n",
    "Xa_screen = Xa\n",
    "Na_screen = Xa.shape[0]\n",
    "\n",
    "ref_ant = Xa[0, :]\n",
    "Na = len(antennas)\n",
    "keep = []\n",
    "\n",
    "for i in range(0, Na):\n",
    "    if np.all(np.linalg.norm(Xa[i:i + 1, :] - Xa[keep, :], axis=1) > ant_cutoff):\n",
    "        keep.append(i)\n",
    "\n",
    "logging.info(\"Training on {} antennas\".format(len(keep)))\n",
    "\n",
    "###\n",
    "# Load data\n",
    "\n",
    "\n",
    "select['ant'] = keep\n",
    "datapack.select(**select)\n",
    "tec, axes = datapack.tec\n",
    "tec -= tec[:, ref_dir_idx:ref_dir_idx + 1, :, :]\n",
    "tec_uncert, _ = datapack.weights_tec\n",
    "\n",
    "# Nd, Na, Nt -> Nt, Nd, Na\n",
    "tec = tec[0, ...].transpose((2, 0, 1))\n",
    "tec_uncert = tec_uncert[0, ...].transpose((2, 0, 1))\n",
    "\n",
    "Nt, Nd, Na = tec.shape\n",
    "_, times = datapack.get_times(axes['time'])\n",
    "Xt = (times.mjd * 86400.)[:, None]\n",
    "_, directions = datapack.get_directions(axes['dir'])\n",
    "Xd = np.stack([directions.ra.to(angle_type).value, directions.dec.to(angle_type).value], axis=1)\n",
    "ref_dir = Xd[ref_dir_idx, :]\n",
    "_, antennas = datapack.get_antennas(axes['ant'])\n",
    "Xa = antennas.cartesian.xyz.to(dist_type).value.T\n",
    "\n",
    "datapack.current_solset = 'screen_posterior'\n",
    "datapack.select(**select)\n",
    "axes = datapack.axes_tec\n",
    "_, screen_directions = datapack.get_directions(axes['dir'])\n",
    "Xd_screen = np.stack([screen_directions.ra.to(angle_type).value, screen_directions.dec.to(angle_type).value], axis=1)\n",
    "Nd_screen = Xd_screen.shape[0]\n",
    "# Xd_screen = np.stack([np.random.uniform(-6*np.pi/180., 6.*np.pi/180.,size=Nd_screen) + directions.ra.to(angle_type).value.mean(),\n",
    "#                       np.random.uniform(-6*np.pi/180., 6.*np.pi/180.,size=Nd_screen) + directions.dec.to(angle_type).value.mean()],axis=1)\n",
    "\n",
    "import os\n",
    "output_folder = './screen_figs_2'\n",
    "os.makedirs(output_folder,exist_ok=True)\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "\n",
    "        with gp.defer_build():\n",
    "            kern = DTECKernel(13, variance=1., lengthscales=10.0,\n",
    "                              a=200., b=100., resolution=4,\n",
    "                              fed_kernel='M52', obs_type='DDTEC')\n",
    "            kern.lengthscales.prior = gp.priors.Gaussian(15., 4. ** 2)\n",
    "            kern.a.prior = gp.priors.Gaussian(250., 100. ** 2)\n",
    "            kern.b.prior = gp.priors.Gaussian(100., 50. ** 2)\n",
    "            kern.variance.prior = gp.priors.Gaussian(5., 2. ** 2)\n",
    "            kern.variance = 3.5 ** 2\n",
    "            kern.lengthscales = 10.\n",
    "            kern.a = 160.\n",
    "            kern.a.trainable = True\n",
    "            kern.b = 100.\n",
    "            kern.b.trainable = False\n",
    "\n",
    "        posterior_screen_mean = []\n",
    "        posterior_screen_std = []\n",
    "        outlier_masks = []\n",
    "\n",
    "        # assumes K doesn't change over this time\n",
    "\n",
    "        for t in range(0, Nt, block_size):\n",
    "            start = t\n",
    "            stop = min(Nt, t + block_size)\n",
    "            mid_time = start + (stop - start) // 2\n",
    "\n",
    "            X = make_coord_array(Xt[mid_time:mid_time + 1], Xd, Xa, flat=False)[0, ...]\n",
    "            X = sess.run(ITRSToENUWithReferences(ref_ant, ref_dir, ref_ant)(X))\n",
    "            X = X.reshape((-1, 13))\n",
    "\n",
    "            X_screen = make_coord_array(Xt[mid_time:mid_time + 1, :], Xd_screen, Xa_screen, flat=False)[0, ...]\n",
    "            X_screen = sess.run(ITRSToENUWithReferences(ref_ant, ref_dir, ref_ant)(X_screen))\n",
    "            X_screen = X_screen.reshape((-1, 13))\n",
    "\n",
    "            # T, N\n",
    "            Y = tec[start:stop, :, :].reshape((stop - start, -1))\n",
    "            # T, N\n",
    "            detection = tec_uncert[start:stop, :, :].reshape((stop - start, -1))\n",
    "            detection = np.where(detection == np.inf, True, False)\n",
    "\n",
    "            if recalculate_weights:\n",
    "                ###\n",
    "                # First outlier filter\n",
    "\n",
    "                Y_var = 10. ** 2 * np.ones_like(Y)\n",
    "\n",
    "                model = HGPR(X, Y, Y_var, kern)\n",
    "                ystar, varstar = model.predict_f(X)\n",
    "                stdstar = np.sqrt(varstar)\n",
    "                outliers = np.abs(ystar - Y) > 10.\n",
    "                cdf_outliers = 0.5 * (1. + erf((Y[outliers] - ystar[outliers]) / stdstar[outliers] / np.sqrt(2.)))\n",
    "                print(np.mean(cdf_outliers), np.std(cdf_outliers))\n",
    "                cdf = 0.5 * (1. + erf((Y - ystar) / stdstar / np.sqrt(2.)))\n",
    "\n",
    "                detection = cdf > np.mean(cdf_outliers)\n",
    "                detection = outliers\n",
    "                mask = np.logical_not(detection)\n",
    "                logging.info(\"First round of filtering: {} outliers\".format(detection.sum()))\n",
    "                Y_var = np.where(detection, np.inf, 1.)\n",
    "\n",
    "                ###\n",
    "                # Refined outlier filter\n",
    "                model = HGPR(X, Y, Y_var, kern)\n",
    "                ystar, varstar = model.predict_f(X)\n",
    "                stdstar = np.sqrt(varstar)\n",
    "                outliers = np.abs(ystar - Y) > 10.\n",
    "\n",
    "                cdf_outliers = 0.5 * (1. + erf((Y[outliers] - ystar[outliers]) / stdstar[outliers] / np.sqrt(2.)))\n",
    "                print(np.mean(cdf_outliers), np.std(cdf_outliers))\n",
    "                cdf = 0.5 * (1. + erf((Y - ystar) / stdstar / np.sqrt(2.)))\n",
    "                detection = cdf > np.mean(cdf_outliers)\n",
    "                detection = outliers\n",
    "                mask = np.logical_not(detection)\n",
    "                logging.info(\"Second round of filtering: {} outliers\".format(detection.sum()))\n",
    "\n",
    "            ###\n",
    "            # Predict\n",
    "            logging.info(\"Predicting with {} outliers\".format(detection.sum()))\n",
    "            Y_var = np.where(detection, np.inf, 0.5)\n",
    "            model = HGPR(X, Y, Y_var, kern, parallel_iterations=10)\n",
    "            logging.info(\"Index {} -> training hyperparams\".format(t))\n",
    "            best_hyperparams = [[np.sqrt(kern.variance.value), kern.lengthscales.value]]\n",
    "            best_log_marginal = model.compute_log_likelihood()\n",
    "            logging.info(\"Doing bayesian optimisation\")\n",
    "            space = [{'name': 'sigma', 'type': 'continuous', 'domain': (0.5, 8.)},\n",
    "                     {'name': 'lengthscale', 'type': 'continuous', 'domain': (1., 30.)},\n",
    "                    {'name': 'a', 'type': 'continuous', 'domain': (100., 400.)}]\n",
    "\n",
    "            #                    {'name': 'wild','type':'discrete', 'domain':(0,1)}]\n",
    "            feasible_region = GPyOpt.Design_space(space=space)\n",
    "            initial_design = GPyOpt.experiment_design.initial_design('random', feasible_region, 30)\n",
    "            initial_design = np.array([[np.sqrt(kern.variance.value), kern.lengthscales.value, kern.a.value]] + list(initial_design))\n",
    "\n",
    "\n",
    "            def opt_func(args):\n",
    "                sigma, lengthscale, a = args[0, 0], args[0, 1], args[0, 2]\n",
    "                kern.lengthscales = lengthscale  # if wild == 0 else lengthscale*10.\n",
    "                kern.variance = sigma ** 2\n",
    "                kern.a = a\n",
    "                lml = model.compute_log_likelihood()\n",
    "                return -lml\n",
    "\n",
    "\n",
    "            # --- CHOOSE the objective\n",
    "            objective = GPyOpt.core.task.SingleObjective(opt_func)\n",
    "\n",
    "            # --- CHOOSE the model type\n",
    "            bo_model = GPyOpt.models.GPModel(exact_feval=True, optimize_restarts=10, verbose=False)\n",
    "\n",
    "            # --- CHOOSE the acquisition optimizer\n",
    "            aquisition_optimizer = GPyOpt.optimization.AcquisitionOptimizer(feasible_region)\n",
    "\n",
    "            # --- CHOOSE the type of acquisition\n",
    "            acquisition = GPyOpt.acquisitions.AcquisitionEI(bo_model, feasible_region, optimizer=aquisition_optimizer)\n",
    "\n",
    "            # --- CHOOSE a collection method\n",
    "            evaluator = GPyOpt.core.evaluators.Sequential(acquisition)\n",
    "            bo = GPyOpt.methods.ModularBayesianOptimization(bo_model, feasible_region, objective, acquisition,\n",
    "                                                            evaluator, initial_design)\n",
    "            # --- Stop conditions\n",
    "            max_time = None\n",
    "            max_iter = 10\n",
    "            tolerance = 1e-5  # distance between two consecutive observations\n",
    "\n",
    "            # Run the optimization\n",
    "            bo.run_optimization(max_iter=max_iter, max_time=max_time, eps=tolerance, verbosity=True)\n",
    "            sigma, lengthscale, a = bo.x_opt\n",
    "            kern.lengthscales = lengthscale  # if wild == 0 else lengthscale*10.\n",
    "            kern.variance = sigma ** 2\n",
    "            kern.a = a\n",
    "\n",
    "            #            logging.info(\"Trying multiple random initialisation...\")\n",
    "            #\n",
    "            #            for _ in range(30):\n",
    "            #                s = np.random.uniform(1.,7.)\n",
    "            #                l = np.random.uniform(2., 25.)\n",
    "            #                kern.lengthscales = l\n",
    "            #                kern.variance = s**2\n",
    "            #                lml = model.compute_log_likelihood()\n",
    "            #                if lml > best_log_marginal:\n",
    "            #                    best_hyperparams.append([s,l])\n",
    "            #                    best_log_marginal = lml\n",
    "            #                    logging.info(\"Found good combo ({}): amp {} lengthscale {}\".format(lml, s,l))\n",
    "            #            kern.lengthscales = best_hyperparams[-1][1]\n",
    "            #            kern.variance = best_hyperparams[-1][0]**2\n",
    "            #            gp.train.ScipyOptimizer().minimize(model)\n",
    "\n",
    "            logging.info(str(kern.read_trainables()))\n",
    "            logging.info(\"Done index {} -> training hyperparams\".format(t))\n",
    "            Y_var = np.where(detection, np.inf, 0.5)\n",
    "            model = HGPR(X, Y, Y_var, kern, parallel_iterations=10)\n",
    "\n",
    "            logging.info(\"Predicting screen from {} to {}\".format(start, stop))\n",
    "            predict_batch_size = 3000\n",
    "            ystar, varstar = [], []\n",
    "            for i in range(0, X_screen.shape[0], predict_batch_size):\n",
    "                start_ = i\n",
    "                stop_ = min(i + predict_batch_size, X_screen.shape[0])\n",
    "                ystar_, varstar_ = model.predict_f(X_screen[start_:stop_, :])\n",
    "                ystar.append(ystar_)\n",
    "                varstar.append(varstar_)\n",
    "            ystar = np.concatenate(ystar, axis=1)\n",
    "            varstar = np.concatenate(varstar, axis=1)\n",
    "            logging.info(\"Done predicting screen from {} to {}\".format(start, stop))\n",
    "\n",
    "            ystar = ystar.reshape((stop - start, Nd_screen, Na_screen))\n",
    "            stdstar = np.sqrt(varstar).reshape((stop - start, Nd_screen, Na_screen))\n",
    "\n",
    "            posterior_screen_mean.append(ystar)\n",
    "            posterior_screen_std.append(stdstar)\n",
    "            \n",
    "            \n",
    "            ###\n",
    "            # plot\n",
    "            ra = Xd[:, 0] * 180 / np.pi\n",
    "            dec = Xd[:, 1] * 180. / np.pi\n",
    "            points = Xd_screen * 180. / np.pi\n",
    "            print(\"Plotting {}\".format(start))\n",
    "            for a in range(Na_screen):\n",
    "                \n",
    "                vmin = ystar[0, :, a].min()\n",
    "                vmax = ystar[0, :, a].max()\n",
    "                plot_vornoi_map(points, ystar[0, :, a], norm=plt.Normalize(vmin, vmax), cmap=plt.cm.gist_rainbow)\n",
    "                if a in keep:\n",
    "                    ka = keep.index(a)\n",
    "                    detection_mask = detection.reshape((stop - start, Nd, Na))[0, :, ka]\n",
    "                    plt.scatter(ra, dec, s=30., c=tec[start, :, ka], cmap=plt.cm.gist_rainbow, vmin=vmin, vmax=vmax,\n",
    "                                edgecolors='black', zorder=18)\n",
    "                    plt.scatter(ra[detection_mask], dec[detection_mask], s=100., c=tec[start, detection_mask, ka],\n",
    "                                cmap=plt.cm.gist_rainbow, vmin=vmin, vmax=vmax, edgecolors='black',zorder=19)\n",
    "                plt.title(\"{} vmin:{:.2f} vmax:{:.2f}\\n{}\".format(ants[a],vmin,vmax, \"\\n\".join([\"{} : {:.2f}\".format(key,value) for key,value in kern.read_trainables().items()])))\n",
    "                plt.xlim(ra.max() + 1, ra.min() - 1)\n",
    "                plt.ylim(dec.min() - 1, dec.max() + 1)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(output_folder,'fig-{:03d}-{:02d}.png'.format(start, a)))\n",
    "                plt.close('all')\n",
    "        #         outlier_masks.append(detection.reshape((stop-start, Nd, Na)))\n",
    "        posterior_screen_mean = np.concatenate(posterior_screen_mean, axis=0).transpose((1, 2, 0))[None, :, :, :]\n",
    "        posterior_screen_std = np.concatenate(posterior_screen_std, axis=0).transpose((1, 2, 0))[None, :, :, :]\n",
    "    #     outlier_masks = np.concatenate(outlier_masks,axis=0).transpose((1,2,0))[None, :,:,:]\n",
    "\n",
    "logging.info(\"Storing\")\n",
    "datapack = DataPack(reinout_datapack, readonly=False)\n",
    "select = dict(pol=slice(0, 1, 1),\n",
    "              ant=slice(None, None, 1),\n",
    "              dir=slice(None, None, 1),\n",
    "              time=slice(None, None, 1))\n",
    "datapack.current_solset = 'screen_posterior'\n",
    "datapack.select(**select)\n",
    "datapack.tec = posterior_screen_mean\n",
    "datapack.weights_tec = posterior_screen_std\n",
    "logging.info(\"Done\")\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 0\n",
      "Plotting 20\n",
      "Plotting 40\n",
      "Plotting 60\n",
      "Plotting 80\n",
      "Plotting 100\n",
      "Plotting 120\n",
      "Plotting 140\n",
      "Plotting 160\n",
      "Plotting 180\n",
      "Plotting 200\n",
      "Plotting 220\n",
      "Plotting 240\n",
      "Plotting 260\n",
      "Plotting 280\n",
      "Plotting 300\n",
      "Plotting 320\n",
      "Plotting 340\n",
      "Plotting 360\n",
      "Plotting 380\n",
      "Plotting 400\n",
      "Plotting 420\n",
      "Plotting 440\n",
      "Plotting 460\n",
      "Plotting 480\n",
      "Plotting 500\n",
      "Plotting 520\n",
      "Plotting 540\n",
      "Plotting 560\n",
      "Plotting 580\n",
      "Plotting 600\n",
      "Plotting 620\n",
      "Plotting 640\n",
      "Plotting 660\n",
      "Plotting 680\n",
      "Plotting 700\n",
      "Plotting 720\n",
      "Plotting 740\n",
      "Plotting 760\n",
      "Plotting 780\n",
      "Plotting 800\n",
      "Plotting 820\n",
      "Plotting 840\n",
      "Plotting 860\n",
      "Plotting 880\n",
      "Plotting 900\n",
      "Plotting 920\n",
      "Plotting 940\n"
     ]
    }
   ],
   "source": [
    "select['ant'] = None\n",
    "keep = list(range(62))\n",
    "datapack.select(**select)\n",
    "datapack.current_solset = 'data_posterior'\n",
    "tec, axes = datapack.tec\n",
    "tec -= tec[:, ref_dir_idx:ref_dir_idx + 1, :, :]\n",
    "tec_uncert, _ = datapack.weights_tec\n",
    "\n",
    "_, direction = datapack.get_directions(axes['dir'])\n",
    "ra = directions.ra.deg\n",
    "dec = directions.dec.deg\n",
    "\n",
    "shape = posterior_screen_mean.shape\n",
    "detection = np.where(tec_uncert == np.inf, True, False)\n",
    "for start in range(0,shape[-1], 20):\n",
    "    print(\"Plotting {}\".format(start))\n",
    "    for a in range(Na_screen):\n",
    "        detection_mask = detection[0, :, a, start]\n",
    "\n",
    "        vmin = tec[0, np.logical_not(detection_mask), a, start].min()\n",
    "        vmax = tec[0, np.logical_not(detection_mask), a, start].max()\n",
    "        plot_vornoi_map(points, posterior_screen_mean[0, :, a, start], norm=plt.Normalize(vmin, vmax), cmap=plt.cm.gist_rainbow)\n",
    "        if a in keep:\n",
    "            ka = keep.index(a)\n",
    "            \n",
    "            plt.scatter(ra, dec, s=30., c=tec[0, :, ka, start], cmap=plt.cm.gist_rainbow, vmin=vmin, vmax=vmax,\n",
    "                        edgecolors='black', zorder=18)\n",
    "            plt.scatter(ra[detection_mask], dec[detection_mask], s=100., c=tec[0, detection_mask, ka, start],\n",
    "                        cmap=plt.cm.gist_rainbow, vmin=vmin, vmax=vmax, edgecolors='black',zorder=19)\n",
    "        plt.title(\"{} vmin:{:.2f} vmax:{:.2f}\".format(ants[a],vmin,vmax))\n",
    "        plt.xlim(ra.max() + 1, ra.min() - 1)\n",
    "        plt.ylim(dec.min() - 1, dec.max() + 1)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder,'fig-{:03d}-{:02d}.png'.format(start, a)))\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_datapack = DataPack('/net/rijn/data2/rvweeren/P126+65_recall/ClockTEC/P126+65_full_compact_ampphasesmoothed.h5', readonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_datapack.current_solset = 'sol000'\n",
    "select = dict(pol=slice(0, 1, 1),\n",
    "              ant=slice(None, None, 1),\n",
    "              dir=slice(None, None, 1),\n",
    "              time=slice(None, None, 1))\n",
    "res_datapack.select(**select)\n",
    "cal_phase, axes = res_datapack.phase\n",
    "cal_amp, _ = res_datapack.amplitude\n",
    "_, cal_directions = res_datapack.get_directions(axes['dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapack.current_solset = 'sol000'\n",
    "datapack.select(**select)\n",
    "phase, _ = datapack.phase\n",
    "\n",
    "\n",
    "datapack.current_solset = 'screen_posterior'\n",
    "datapack.select(**select)\n",
    "axes = datapack.axes_phase\n",
    "antenna_labels, _ = datapack.get_antennas(axes['ant'])\n",
    "patch_names, _ = datapack.get_directions(axes['dir'])\n",
    "pols, _ = datapack.get_pols(axes['pol'])\n",
    "\n",
    "_, freqs = datapack.get_freqs(axes['freq'])\n",
    "_, screen_directions = datapack.get_directions(axes['dir'])\n",
    "tec, _ = datapack.tec\n",
    "phase_posterior = tec[...,None,:]*-8.448e6/freqs[:,None] + phase[:,14:15,...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_Xd = np.stack([cal_directions.ra.deg, cal_directions.dec.deg],axis=1)\n",
    "screen_Xd = np.stack([screen_directions.ra.deg, screen_directions.dec.deg],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0719 23:19:21.483617 140342669231936 datapack.py:203] Deleted solset concat_posterior.\n",
      "I0719 23:19:21.496034 140342669231936 datapack.py:218] Created antenna table.\n",
      "I0719 23:19:21.512750 140342669231936 datapack.py:247] Set the antenna table.\n",
      "I0719 23:19:21.515606 140342669231936 datapack.py:234] Created direction table.\n",
      "I0719 23:19:21.516950 140342669231936 datapack.py:145] Created solset concat_posterior.\n",
      "I0719 23:19:21.526135 140342669231936 datapack.py:261] Set the direction table.\n",
      "I0719 23:19:29.316180 140342669231936 datapack.py:184] Created soltab phase000\n",
      "I0719 23:19:38.365258 140342669231936 datapack.py:184] Created soltab amplitude000\n"
     ]
    }
   ],
   "source": [
    "#screen_Xd is [Nd_screen, 2] ra and dec of screens in deg\n",
    "#cal_Xd is [Nd_cals,2] ra and dec of cals in deg\n",
    "from scipy.spatial import cKDTree\n",
    "kd = cKDTree(cal_Xd)\n",
    "dist, idx = kd.query(screen_Xd,k=1)\n",
    "keep_screen = dist*60 > 0.5\n",
    "\n",
    "mjs_times = times.mjd*86400.\n",
    "\n",
    "\n",
    "concat_Xd = np.concatenate([cal_Xd, screen_Xd[keep_screen, :]],axis=0)\n",
    "concat_phase = np.concatenate([cal_phase, phase_posterior[:,keep_screen, ...]], axis=1)\n",
    "dist, idx = kd.query(concat_Xd,k=1)\n",
    "\n",
    "concat_amp = cal_amp[:, idx, ...]\n",
    "\n",
    "if 'concat_posterior' in datapack.solsets:\n",
    "    datapack.delete_solset('concat_posterior')\n",
    "    \n",
    "datapack.add_solset('concat_posterior')\n",
    "datapack.set_directions(None, concat_Xd*np.pi/180.)\n",
    "    \n",
    "datapack.current_solset = 'concat_posterior'\n",
    "antenna_labels, _ = datapack.antennas\n",
    "patch_names, _ = datapack.directions\n",
    "\n",
    "datapack.add_soltab('phase000', values = concat_phase, \n",
    "                    ant=antenna_labels, dir=patch_names, time=mjs_times, freq=freqs, pol=pols)\n",
    "\n",
    "datapack.add_soltab('amplitude000', values = concat_amp, \n",
    "                    ant=antenna_labels, dir=patch_names, time=mjs_times, freq=freqs, pol=pols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase, _ = datapack.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 175, 62, 24, 960)\n"
     ]
    }
   ],
   "source": [
    "print(phase.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_directions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
